{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installation et Import des Biblioth√®ques\n",
    "Installation et import des biblioth√®ques n√©cessaires: transformers, torch, pandas, numpy. Configuration des mod√®les BERT multilingue et BERT standard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/python/3.12.1/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "BertForMaskedLM has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From üëâv4.50üëà onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Importer les biblioth√®ques n√©cessaires\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertForTokenClassification, BertForMaskedLM\n",
    "\n",
    "# Configurer les mod√®les BERT\n",
    "tokenizer_multilingual = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
    "model_multilingual = BertForTokenClassification.from_pretrained('bert-base-multilingual-cased')\n",
    "\n",
    "tokenizer_standard = BertTokenizer.from_pretrained('bert-base-cased')\n",
    "model_standard = BertForMaskedLM.from_pretrained('bert-base-cased')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chargement des Mod√®les Transformers\n",
    "Chargement de bert-base-multilingual-cased pour le POS tagging et bert-base-cased pour la s√©lection des mots. Configuration des tokenizers et des pipelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement des Mod√®les Transformers\n",
    "\n",
    "# Importer les biblioth√®ques n√©cessaires\n",
    "from transformers import pipeline\n",
    "\n",
    "# Configurer les pipelines pour l'analyse grammaticale et la s√©lection des mots\n",
    "pos_tagger = pipeline('ner', model=model_multilingual, tokenizer=tokenizer_multilingual)\n",
    "word_replacer = pipeline('fill-mask', model=model_standard, tokenizer=tokenizer_standard)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identification des Verbes avec POS Tagging\n",
    "Utilisation du mod√®le BERT multilingue pour identifier les verbes dans les proverbes modifi√©s via l'analyse grammaticale (POS tagging)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'entity': 'LABEL_1', 'score': np.float32(0.57922167), 'index': 1, 'word': 'Les', 'start': None, 'end': None}, {'entity': 'LABEL_1', 'score': np.float32(0.68530345), 'index': 2, 'word': 'actes', 'start': None, 'end': None}, {'entity': 'LABEL_1', 'score': np.float32(0.6509647), 'index': 3, 'word': 'vale', 'start': None, 'end': None}, {'entity': 'LABEL_1', 'score': np.float32(0.67500263), 'index': 4, 'word': '##nt', 'start': None, 'end': None}, {'entity': 'LABEL_1', 'score': np.float32(0.63514495), 'index': 5, 'word': 'mieux', 'start': None, 'end': None}, {'entity': 'LABEL_1', 'score': np.float32(0.67442673), 'index': 6, 'word': 'que', 'start': None, 'end': None}, {'entity': 'LABEL_1', 'score': np.float32(0.6825574), 'index': 7, 'word': 'les', 'start': None, 'end': None}, {'entity': 'LABEL_1', 'score': np.float32(0.7003117), 'index': 8, 'word': 'paroles', 'start': None, 'end': None}]\n",
      "[{'entity': 'LABEL_1', 'score': np.float32(0.5686393), 'index': 1, 'word': 'Les', 'start': None, 'end': None}, {'entity': 'LABEL_1', 'score': np.float32(0.6700878), 'index': 2, 'word': 'actes', 'start': None, 'end': None}, {'entity': 'LABEL_1', 'score': np.float32(0.6436921), 'index': 3, 'word': 'mange', 'start': None, 'end': None}, {'entity': 'LABEL_1', 'score': np.float32(0.688892), 'index': 4, 'word': '##nt', 'start': None, 'end': None}, {'entity': 'LABEL_1', 'score': np.float32(0.6504412), 'index': 5, 'word': 'mieux', 'start': None, 'end': None}, {'entity': 'LABEL_1', 'score': np.float32(0.6820028), 'index': 6, 'word': 'que', 'start': None, 'end': None}, {'entity': 'LABEL_1', 'score': np.float32(0.6705369), 'index': 7, 'word': 'les', 'start': None, 'end': None}, {'entity': 'LABEL_1', 'score': np.float32(0.6856153), 'index': 8, 'word': 'paroles', 'start': None, 'end': None}]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[], []]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fonction pour identifier les verbes dans les proverbes modifi√©s\n",
    "def identify_verbs(proverbs):\n",
    "    verb_positions = []\n",
    "    for proverb in proverbs:\n",
    "        masked_proverb = proverb['Masked']\n",
    "        tokens = pos_tagger(masked_proverb)\n",
    "        # Print tokens to see the actual entity labels\n",
    "        print(tokens)\n",
    "        verbs = [token for token in tokens if 'VERB' in token['entity']]\n",
    "        verb_positions.append(verbs)\n",
    "    return verb_positions\n",
    "\n",
    "# Proverbes modifi√©s pour les tests\n",
    "tests = [{'Masked': 'Les actes valent mieux que les paroles'},\n",
    "         {'Masked': 'Les actes mangent mieux que les paroles'}]\n",
    "    \n",
    "# Identifier les verbes dans les proverbes modifi√©s\n",
    "verb_positions = identify_verbs(tests)\n",
    "\n",
    "# Afficher les positions des verbes identifi√©s\n",
    "verb_positions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# S√©lection du Meilleur Mot\n",
    "Utilisation du mod√®le BERT pour calculer la probabilit√© de chaque mot candidat dans le contexte du proverbe et s√©lectionner le plus appropri√©."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# S√©lection du Meilleur Mot\n",
    "\n",
    "# Fonction pour remplacer les verbes identifi√©s par les mots candidats et s√©lectionner le meilleur mot\n",
    "def correct_proverbs(proverbs, verb_positions):\n",
    "    corrected_proverbs = []\n",
    "    for i, proverb in enumerate(proverbs):\n",
    "        masked_proverb = proverb['Masked']\n",
    "        word_list = proverb['Word_list']\n",
    "        best_proverb = masked_proverb\n",
    "        best_score = float('-inf')\n",
    "        \n",
    "        for word in word_list:\n",
    "            # Remplacer le verbe par le mot candidat\n",
    "            for verb in verb_positions[i]:\n",
    "                start, end = verb['start'], verb['end']\n",
    "                masked_proverb = masked_proverb[:start] + '[MASK]' + masked_proverb[end:]\n",
    "                masked_proverb = masked_proverb.replace('[MASK]', word, 1)\n",
    "                \n",
    "                # Calculer la probabilit√© du proverbe avec le mot candidat\n",
    "                inputs = tokenizer_standard(masked_proverb, return_tensors='pt')\n",
    "                outputs = model_standard(**inputs)\n",
    "                logits = outputs.logits\n",
    "                mask_token_index = torch.where(inputs.input_ids == tokenizer_standard.mask_token_id)[1]\n",
    "                mask_token_logits = logits[0, mask_token_index, :]\n",
    "                top_token = torch.topk(mask_token_logits, 1, dim=1).indices[0].tolist()\n",
    "                \n",
    "                # V√©rifier si le mot candidat est le meilleur\n",
    "                if word in tokenizer_standard.convert_ids_to_tokens(top_token):\n",
    "                    score = mask_token_logits[0, tokenizer_standard.convert_tokens_to_ids(word)].item()\n",
    "                    if score > best_score:\n",
    "                        best_score = score\n",
    "                        best_proverb = masked_proverb\n",
    "        \n",
    "        corrected_proverbs.append(best_proverb)\n",
    "    return corrected_proverbs\n",
    "\n",
    "# Corriger les proverbes\n",
    "corrected_proverbs = correct_proverbs(tests, verb_positions)\n",
    "\n",
    "# Afficher les proverbes corrig√©s\n",
    "corrected_proverbs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# √âvaluation et Analyse des R√©sultats\n",
    "√âvaluation de la performance du syst√®me, calcul des m√©triques et analyse comparative avec l'approche du TP1. Analyse qualitative des erreurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# √âvaluation et Analyse des R√©sultats\n",
    "\n",
    "# Fonction pour √©valuer la performance du syst√®me\n",
    "def evaluate_performance(corrected_proverbs, original_proverbs):\n",
    "    correct_count = 0\n",
    "    total_count = len(original_proverbs)\n",
    "    \n",
    "    for corrected, original in zip(corrected_proverbs, original_proverbs):\n",
    "        if corrected == original['Proverb']:\n",
    "            correct_count += 1\n",
    "    \n",
    "    accuracy = correct_count / total_count\n",
    "    return accuracy\n",
    "\n",
    "# Calculer la pr√©cision du syst√®me\n",
    "accuracy = evaluate_performance(corrected_proverbs, tests)\n",
    "\n",
    "# Afficher la pr√©cision\n",
    "print(f\"Pr√©cision du syst√®me: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Analyse comparative avec l'approche du TP1\n",
    "# (Cette section est un exemple et doit √™tre remplie avec les r√©sultats r√©els du TP1)\n",
    "accuracy_tp1 = 0.85  # Exemple de pr√©cision du TP1\n",
    "\n",
    "print(f\"Pr√©cision de l'approche du TP1: {accuracy_tp1 * 100:.2f}%\")\n",
    "print(f\"Am√©lioration de la pr√©cision: {(accuracy - accuracy_tp1) * 100:.2f}%\")\n",
    "\n",
    "# Analyse qualitative des erreurs\n",
    "def analyze_errors(corrected_proverbs, original_proverbs):\n",
    "    errors = []\n",
    "    for corrected, original in zip(corrected_proverbs, original_proverbs):\n",
    "        if corrected != original['Proverb']:\n",
    "            errors.append({\n",
    "                'Masked': original['Masked'],\n",
    "                'Corrected': corrected,\n",
    "                'Original': original['Proverb']\n",
    "            })\n",
    "    return errors\n",
    "\n",
    "# Obtenir les erreurs\n",
    "errors = analyze_errors(corrected_proverbs, tests)\n",
    "\n",
    "# Afficher les erreurs\n",
    "for error in errors:\n",
    "    print(f\"Proverbe masqu√©: {error['Masked']}\")\n",
    "    print(f\"Proverbe corrig√©: {error['Corrected']}\")\n",
    "    print(f\"Proverbe original: {error['Original']}\")\n",
    "    print(\"---\")\n",
    "\n",
    "# Analyse des erreurs\n",
    "# (Cette section est un exemple et doit √™tre remplie avec une analyse r√©elle des erreurs)\n",
    "print(\"Analyse des erreurs:\")\n",
    "print(\"1. Les erreurs peuvent √™tre dues √† une mauvaise identification des verbes.\")\n",
    "print(\"2. Les erreurs peuvent √©galement √™tre dues √† une mauvaise s√©lection des mots candidats.\")\n",
    "print(\"3. Certaines erreurs peuvent √™tre dues √† des proverbes moins courants ou √† des variations r√©gionales.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
